---
layout: post
title: Memcache 调研
date: 2012-03-08 10:59:44.000000000 +00:00
type: post
published: true
status: publish
categories:
- java
- Web
- "分布式"
tags:
- Memcache
meta:
  views: '178'
author:
  login: ig2net
  email: ig2net@ig2net.info
  display_name: "农夫一号"
  first_name: ''
  last_name: ''
---
<p>官网:<a href="http://memcached.org/">http://memcached.org/</a></p>
<p>文档:<a href="http://code.google.com/p/memcached/wiki/NewStart?tm=6">http://code.google.com/p/memcached/wiki/NewStart?tm=6</a></p>
<p>这位<a href="http://www.cnblogs.com/Jwin/archive/2008/10/05/1304261.html" target="_blank">仁兄</a>收集了些文章:</p>
<p><a href="http://kb.cnblogs.com/page/42775/">分布式缓存系统Memcached简介与实践</a></p>
<p><a href="http://blog.ureshika.com/archives/750.html">Memcached深度分析</a>&#160;<font color="#0000ff">[好文，必读]</font></p>
<p><a href="http://kb.cnblogs.com/page/42777/">自己实现memcached客户端库</a></p>
<p><a href="http://www.javaeye.com/topic/225692">memcached server LRU 深入分析</a><font color="#0000ff">[这个针对实际问题阐述memcached内存存储的调整，回头再看</font><a href="http://blog.ureshika.com/archives/750.html"><font color="#0000ff">Memcached深度分析</font></a><font color="#0000ff"> ]</font></p>
<p><a href="http://blog.csdn.net/heiyeshuwu/article/details/3950532"><font color="#0000ff">Memcached 原理和使用详解(PPT/PDF)</font></a>&#160;<font color="#0000ff">[这个写的很好,必读]</font></p>
<p><a href="http://kb.cnblogs.com/page/42790/">Memcached使用点滴</a>&#160;<font color="#0000ff">[这个需要对memcache有一定了解之后，打算自己实现client可做借鉴]</font></p>
<p><a href="http://tech.idv2.com/2008/08/17/memcached-pdf/">memcached全面剖析–PDF总结篇</a>&#160;<font color="#0000ff">[very good,日本mixi网站工程师写的，国人翻译的]</font></p>
<p>&#160;</p>
<p>api client 列表 <a href="http://code.google.com/p/memcached/wiki/Clients">http://code.google.com/p/memcached/wiki/Clients</a></p>
<p>参见<a title="http://blog.ureshika.com/archives/753.html" href="http://blog.ureshika.com/archives/753.html">http://blog.ureshika.com/archives/753.html</a>&#160;</p>
<p>memcached 安装见<a href="http://www.ccvita.com/257.html">http://www.ccvita.com/257.html</a></p>
<p>以下是我的安装命令[需要root权限]:</p>
<p>------------------------------------------------------------------------------------------------------------</p>
<p>#安装libevent</p>
<p>cd /tmp</p>
<p>wget <a href="http://memcached.googlecode.com/files/memcached-1.4.13.tar.gz">http://memcached.googlecode.com/files/memcached-1.4.13.tar.gz</a></p>
<p>wget --no-check-certificate <a href="https://github.com/downloads/libevent/libevent/libevent-2.0.17-stable.tar.gz">https://github.com/downloads/libevent/libevent/libevent-2.0.17-stable.tar.gz</a></p>
<p>tar zxvf libevent-2.0.17-stable.tar.gz</p>
<p>cd libevent-2.0.17-stable</p>
<p>./configure --prefix=/usr</p>
<p>make</p>
<p>make install</p>
<p>#检查是否安装</p>
<p>ls -al /usr/lib | grep libevent</p>
<p>#安装memcached</p>
<p>tar zxvf memcached-1.4.13.tar.gz</p>
<p>cd memcached-1.4.13</p>
<p>./configure --with-libevent=/usr</p>
<p>make</p>
<p>make install</p>
<p>#测试是否成功安装memcached：</p>
<p>ls -al /usr/local/bin/mem*</p>
<p>#查看12000端口是否被占用</p>
<p>netstat -tl | grep 12000</p>
<p>#启动并将进程号存入memcached.pid</p>
<p>/usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P memcached.pid</p>
<p>#查看配置状态</p>
<p>echo &quot;stats settings&quot; | nc localhost 12000</p>
<p>#查看内存分块状态</p>
<p>echo &quot;stats slabs&quot; | nc localhost 12000</p>
<p>#查看健康状况</p>
<p>echo &quot;stats&quot; | nc localhost 12000</p>
<p>详细参数列表:</p>
<div>
<pre>-p <span style="color: #0000ff">&lt;</span><span style="color: #800000">num</span><span style="color: #0000ff">&gt;</span>      TCP port number to listen on (default: 11211)
-U <span style="color: #0000ff">&lt;</span><span style="color: #800000">num</span><span style="color: #0000ff">&gt;</span>      UDP port number to listen on (default: 11211, 0 is off)
-s <span style="color: #0000ff">&lt;</span><span style="color: #800000">file</span><span style="color: #0000ff">&gt;</span>     UNIX socket path to listen on (disables network support)
-a <span style="color: #0000ff">&lt;</span><span style="color: #800000">mask</span><span style="color: #0000ff">&gt;</span>     access mask for UNIX socket, in octal (default: 0700)
-l <span style="color: #0000ff">&lt;</span><span style="color: #800000">addr</span><span style="color: #0000ff">&gt;</span>     interface to listen on (default: INADDR_ANY, all addresses)
              <span style="color: #0000ff">&lt;</span><span style="color: #800000">addr</span><span style="color: #0000ff">&gt;</span> may be specified as host:port. If you don't specify
              a port number, the value you specified with -p or -U is
              used. You may specify multiple addresses separated by comma
              or by using -l multiple times
-d            run as a daemon
-r            maximize core file limit
-u <span style="color: #0000ff">&lt;</span><span style="color: #800000">username</span><span style="color: #0000ff">&gt;</span> assume identity of <span style="color: #0000ff">&lt;</span><span style="color: #800000">username</span><span style="color: #0000ff">&gt;</span> (only when run as root)
-m <span style="color: #0000ff">&lt;</span><span style="color: #800000">num</span><span style="color: #0000ff">&gt;</span>      max memory to use for items in megabytes (default: 64 MB)
-M            return error on memory exhausted (rather than removing items)
-c <span style="color: #0000ff">&lt;</span><span style="color: #800000">num</span><span style="color: #0000ff">&gt;</span>      max simultaneous connections (default: 1024)
-k            lock down all paged memory.  Note that there is a
              limit on how much memory you may lock.  Trying to
              allocate more than that would fail, so be sure you
              set the limit correctly for the user you started
              the daemon with (not for -u <span style="color: #0000ff">&lt;</span><span style="color: #800000">username</span><span style="color: #0000ff">&gt;</span> user;
              under sh this is done with 'ulimit -S -l NUM_KB').
-v            verbose (print errors/warnings while in event loop)
-vv           very verbose (also print client commands/reponses)
-vvv          extremely verbose (also print internal state transitions)
-h            print this help and exit
-i            print memcached and libevent license
-P <span style="color: #0000ff">&lt;</span><span style="color: #800000">file</span><span style="color: #0000ff">&gt;</span>     save PID in <span style="color: #0000ff">&lt;</span><span style="color: #800000">file</span><span style="color: #0000ff">&gt;</span>, only used with -d option
-f <span style="color: #0000ff">&lt;</span><span style="color: #800000">factor</span><span style="color: #0000ff">&gt;</span>   chunk size growth factor (default: 1.25)
-n <span style="color: #0000ff">&lt;</span><span style="color: #800000">bytes</span><span style="color: #0000ff">&gt;</span>    minimum space allocated for key+value+flags (default: 48)
-L            Try to use large memory pages (if available). Increasing
              the memory page size could reduce the number of TLB misses
              and improve the performance. In order to get large pages
              from the OS, memcached will allocate the total item-cache
              in one large chunk.
-D <span style="color: #0000ff">&lt;</span><span style="color: #800000">char</span><span style="color: #0000ff">&gt;</span>     Use <span style="color: #0000ff">&lt;</span><span style="color: #800000">char</span><span style="color: #0000ff">&gt;</span> as the delimiter between key prefixes and IDs.
              This is used for per-prefix stats reporting. The default is
              &quot;:&quot; (colon). If this option is specified, stats collection
              is turned on automatically; if not, then it may be turned on
              by sending the &quot;stats detail on&quot; command to the server.
-t <span style="color: #0000ff">&lt;</span><span style="color: #800000">num</span><span style="color: #0000ff">&gt;</span>      number of threads to use (default: 4)
-R            Maximum number of requests per event, limits the number of
              requests process for a given connection to prevent 
              starvation (default: 20)
-C            Disable use of CAS
-b            Set the backlog queue limit (default: 1024)
-B            Binding protocol - one of ascii, binary, or auto (default)
-I            Override the size of each slab page. Adjusts max item size
              (default: 1mb, min: 1k, max: 128m)
-o            Comma separated list of extended or experimental options
              - (EXPERIMENTAL) maxconns_fast: immediately close new
                connections if over maxconns limit
              - hashpower: An integer multiplier for how large the hash
                table should be. Can be grown at runtime if not big enough.
                Set this based on &quot;STAT hash_power_level&quot; before a 
                restart.</pre>
</div>
<p>注意<font color="#0000ff">-f</font>&#160; 增量 <font color="#0000ff">-n</font> chunck块初始大小[默认1024b] <font color="#0000ff">-I</font> slab page大小[不能超过slab大小,1k—128M,默认1M]</p>
<p></p>
<p>------------------------------------------------------------------------------------------------------------</p>
<p>以下摘自: <a href="http://blog.csdn.net/heiyeshuwu/article/details/3950532"><font color="#0000ff">Memcached 原理和使用详解(PPT/PDF)</font></a>&#160;</p>
<h6>数据存储方式：Slab Allocation</h6>
<p><strong>Slab Alloction 构造图:</strong></p>
<p><a href="http://blog.ureshika.com/wp-content/uploads/2012/03/image.png"><img style="border-right-width: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px" title="image" border="0" alt="image" src="{{ site.baseurl }}/assets/image_thumb.png" width="417" height="312" /></a></p>
<p>Slab Allocator的基本原理是按照预先规定的大小，将分配的内存分割成特定长度的块，以完全解决内存碎片问题。 </p>
<p>Slab Allocation的原理相当简单。 将分配的内存分割成各种尺寸的块（chunk），并把尺寸相同的块分成组（chunk的集合）</p>
<p><strong>Slab Classes 分配图</strong></p>
<p><a href="http://blog.ureshika.com/wp-content/uploads/2012/03/image1.png"><img style="border-right-width: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px" title="image" border="0" alt="image" src="{{ site.baseurl }}/assets/image_thumb1.png" width="417" height="312" /></a> </p>
<p>Page：分配给Slab的内存空间，默认是1MB。分配给Slab之后根据slab的大小切分成chunk。</p>
<p>Chunk：用于缓存记录的内存空间。</p>
<p>注意:摘自<a href="http://y.jmeye.com/?aid=185">http://y.jmeye.com/?aid=185</a></p>
<p>Slab是一个内存块，它是memcached一次申请内存的最小单位。 在启动memcached的时候一般会使用参数-m指定其可用内存，但是并不是在启动的那一刻所有的内存就全部分配出去了，只有在需要的时候才会去申请， 而且每次申请一定是一个slab。<font color="#0000ff">Slab的大小固定为1M（1048576 Byte</font>），一个slab由若干个大小相等的chunk组成。每个chunk中都保存了一个item结构体、一对key和value。</p>
<p>注意:</p>
<p><strong></strong></p>
<p><font color="#0000ff">chunk中不仅保持了缓存对象的value，而且保存了缓存对象的key，expire time， flag等详细信息</font></p>
<p>参见: <a href="http://tank.blogs.tkiicpp.com/category/programming/memcache/">http://tank.blogs.tkiicpp.com/category/programming/memcache/</a></p>
<p>Slab Class：特定大小的chunk的组。</p>
<p>memcached根据收到的数据的大小，选择最适合数据大小的slab。 </p>
<p>memcached中保存着slab内空闲chunk的列表，根据该列表选择chunk，然后将数据缓存于其中。</p>
<p><strong>Slab Alloction 缺点</strong></p>
<p><a href="http://blog.ureshika.com/wp-content/uploads/2012/03/image2.png"><img style="border-right-width: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px" title="image" border="0" alt="image" src="{{ site.baseurl }}/assets/image_thumb2.png" width="416" height="180" /></a> </p>
<p>这个问题就是，由于分配的是特定长度的内存，因此无法有效利用分配的内存。例如，将100字节的数据缓存到128字节的chunk中，剩余的28字节就浪费了。</p>
<p>&#160;</p>
<p>以下摘自: <a href="http://blog.ureshika.com/archives/750.html">http://blog.ureshika.com/archives/750.html</a></p>
<div>在1.2中，chunk大小表示为初始大小*f^n，f为factor，在memcached.c中定义，n为classid，同时，201个头不是全部 都要初始化的，因为factor可变，初始化只循环到计算出的大小达到slab大小的一半为止，而且它是从id1开始的，即：id为1的slab，每 chunk大小80字节，id为2的slab，每chunk大小80*f，id为3的slab，每chunk大小80*f^2，初始化大小有一个修正值 CHUNK_ALIGN_BYTES，用来保证n-byte排列 （保证结果是CHUNK_ALIGN_BYTES的整倍数）。这样，在标准情况下，memcached1.2会初始化到id40，这个slab中每个 chunk大小为504692，每个slab中有两个chunk。最后，slab_init函数会在最后补足一个id41，它是整块的，也就是这个 slab中只有一个1MB大的chunk</div>
<div>&#160;</div>
<p><font color="#000000">以下摘自:</font> </p>
<p><a href="http://blog.csdn.net/jarfield/article/details/4322953">http://blog.csdn.net/jarfield/article/details/4322953</a> </p>
<p><a href="http://blog.csdn.net/jarfield/article/details/4336035">http://blog.csdn.net/jarfield/article/details/4336035</a> </p>
<p><a href="http://blog.csdn.net/jarfield/article/details/4341819">http://blog.csdn.net/jarfield/article/details/4341819</a> </p>
<p>所有的被发送到memcached的单个命令是完全原子的。如果您针对同一份数据同时发送了一个set命令和一个get命令，它们不会影响对方。它们将被串行化、先后执行。 </p>
<p>通常，基于memcached中item的值来修改item，是一件棘手的事情。除非您很清楚自己在做什么，否则请不要做这样的事情。</p>
<div>&#160;</div>
<div>以下摘自: <a href="http://www.iteye.com/topic/225692">http://www.iteye.com/topic/225692</a></div>
<div><font color="#0000ff">memcached中新的value过来存放的地址是该value的大小决定的，value总是会被选择存放到chunk与其最接近的一个slab中</font>，比如上面的例子，如果我的value是80b，那么我这所有的value总是会被存放到1号slab中，而1号slab中的free_chunks已经是0了，怎么办呢，如果你在启动memcached的时候没有追加-M（禁止LRU，这种情况下内存不够时会out of memory），那么memcached会把这个slab中最近最少被使用的chunk中的数据清掉，然后放上最新的数据。这就解释了为什么我的内存还有40%的时候LRU就执行了，因为我的其他slab中的chunk_size都远大于我的value，所以我的value根本不会放到那几个slab中，而只会放到和我的value最接近的chunk所在的slab中(而这些slab早就满了，郁闷了)。这就导致了我的数据被不停的覆盖，后者覆盖前者。</div>
<div>&#160;</div>
<div><font color="#0000ff">我总结一下:</font></div>
<div><font color="#0000ff">逻辑上的item 存于chunk中，相同大小chunk组成slab(chunk初始值由-n配置), 各个slab大小是一致的(-I配置)，但是slab1和slab2其内部的chunk大小是不同的，slab2内部的chunk大小是slab1内部chunk大小的 f增量子倍(-f配置),另外slab page是将slab划分的内存块,一个slab可划分为多个page,每个page下存储多个chunk</font></div>
<div><font color="#0000ff">逻辑元素: slab,item</font></div>
<div><font color="#0000ff">内存元素:page,chunk</font></div>
<div><font color="#0000ff">这些可通过memcached的状态打印输出看出来</font></div>
<p>STAT 1:chunk_size 80<br />
  <br />STAT 1:chunks_per_page 13107</p>
<p>STAT 1:total_pages 1</p>
<p>STAT 1:total_chunks 13107</p>
<p>STAT 1:used_chunks 13107</p>
<p>STAT 1:free_chunks 0</p>
<p>STAT 1:free_chunks_end 13107</p>
<div>
  <br /><font color="#0000ff">•在 Memcached 中可以保存的item数据量是没有限制的，只有内存足够</font></div>
<p><font color="#0000ff">• 最大键长为250字节，大于该长度无法存储，常量代码中KEY_MAX_LENGTH 250 控制</font></p>
<p><font color="#0000ff">• 单个item最大数据默认是1MB，超过1MB数据不予存储，常量代码POWER_BLOCK 1048576 进行控制，参数-I控制的是slab page大小,因此它不能超过slab大小，slab大小只能通过编译源码来改。</font></p>
<p><font color="#0000ff">32位系统下Memcached单进程最大使用内存为2G，要使用更多内存，可以分多个端口开启多个Memcached进程或改为64位系统。</font></p>
<p></p>
<p>-----------------------------------------------------------------------------</p>
<p>它的接口文档见<a href="http://code.google.com/p/memcached/wiki/NewCommands">http://code.google.com/p/memcached/wiki/NewCommands</a></p>
<p>其中有些还没被Memcached-Java-Client实现，比如cas,可能是新加的接口。</p>
<p><font color="#0000ff">memcached提供的接口目标就是简单，其用起来可以说简单，但是不简单的地方是什么呢，当然他的内部机理比较复杂，最主要的是实际应用场景的相关问题。</font></p>
<p><font color="#0000ff">你做数据缓存，那么哪些数据应该缓存？怎么样缓存？过期策略？</font></p>
<p><font color="#0000ff">做session集群共享，要不要保证可靠性?</font></p>
<p><font color="#0000ff">很多时候不该memcached做的事情也让它来做了，这时可考虑下nosql地盘的东东了。</font></p>
<p>可参考转载的这篇文章：<a title="http://blog.ureshika.com/archives/757.html" href="http://blog.ureshika.com/archives/757.html">http://blog.ureshika.com/archives/757.html</a></p>
