---
layout: post
title: it-e-02 web harvesting
date: 2011-05-26 05:31:24.000000000 +01:00
type: post
published: true
status: publish
categories:
- "英语"
tags:
- english
- it
meta:
  views: '18'
author:
  login: ig2net
  email: ig2net@ig2net.info
  display_name: "农夫一号"
  first_name: ''
  last_name: ''
---
<p>As the amount of information on the Web grows, that information becomes ever harder to   <br />keep track of and use. Search engines are a big help, but they can do only part of the work, and    <br />they are hard-pressed to keep up with daily changes.    <br />Consider that even when you use a search engine to locate data, you still have to do the    <br />following tasks to capture the information you need: scan the content until you find the    <br />information, mark the information (usually by highlighting with a mouse), switch to another    <br />application ( such as a spreadsheet, database or word processor), paste the information into that    <br />application.</p>
<p>A better solution, especially for companies that are aiming to exploit a broad swath of data   <br />about markets or competitors, lies with Web harvesting tools.    <br />Web harvesting software automatically extracts information from the Web and picks up    <br />where search engines leave off, doing the work the search engine can't. Extraction tools automate    <br />the reading, copying and pasting necessary to collect information for analysis, and they have    <br />proved useful for pulling together information on competitors, prices and financial data or all    <br />types.    <br />There are three ways we can extract more useful information from the Web.    <br />The first technique, Web content harvesting, is concerned directly with the specific content    <br />of documents or their descriptions, such as HTML files, images or e-mail messages. Since most    <br />text documents are relatively unstructured (at least as far as machine interpretation is concerned),    <br />one common approach is to exploit what's already known about the general structure of    <br />documents and map this to some data model.    <br />The other approach to Web content harvesting involves trying to improve on the content    <br />searches that tools like search engines perform. This type of content harvesting goes beyond    <br />keyword extraction and the production of simple statistics relating to words and phrases in    <br />documents.    <br />Another technique, Web structure harvesting, takes advantage of the fact that Web pages    <br />can reveal more information than just their obvious content. Links from other sources that point    <br />to a particular Web page indicate the popularity of that page, while links within a Web page that    <br />point to other resources may indicate the richness or variety of topics covered in that page. This    <br />is like analyzing bibliographical citations— paper that's often cited in bibliographies and other    <br />paper is usually considered to be important.    <br />The third technique, Web usage harvesting, uses data recorded by Web servers about user    <br />interactions to help understand user behavior and evaluate the effectiveness of the Web structure.    <br />General access—pattern tracking analyzes Web logs to understand access patterns and    <br />trends in order to identify structural issues and resource groupings.    <br />Customized usage tracking analyzes individual trends so that Web sites can be personalized    <br />to specific users. Over time, based on access patterns, a site can be dynamically customized for a    <br />user in terms of the information displayed , the depth of the site structure and the format of the    <br />resource presented.</p>
